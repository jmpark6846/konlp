1.개발 환경
konlpy
jpype
numpy
python 2.7(64bit)
windows 7

2.형태소 
형태소는 일정한 의미가 있는 가장 작은 말의 단위로 발화체 내에서 따로 떼어낼 수 있는 것을 말한다.
크게 실질형태소, 형식형태소 두가지로 분류할 수 있는데 의미를 나타내는 실질형태소인 명사, 동사, 형용사, 부사를 사용했다.
문장에서 형태소를 얻을 수 있는 '한국어 자연어 처리' 라이브러리인 konlpy를 사용하였다. 사용법은 참조 사이트를 표시해두었으니 사이트를 찬찬히 둘러보자. 

품사 태그 클래스는 한나눔을 사용했다. konlpy에는 이 외에도 Kkma, Komoran, Twitter, Mecab 품사 태깅 클래스를 지원한다. (mecab를 쓰고싶었으나 window에서 안된다고해서 못썼다. 시무룩.)

품사를 9가지로 나누거나, 혹은 22가지로 더 자세하게 나눌 수 있는데 각각 hannanum_analyze, hannanum_analyze_22 함수이니 원하는 것을 사용하면 된다. 여기선 22 품사일때를 사용.

9tags 일때는 체언N(=명사) 용언P(=동사, 형용사), 수식언M(=관형사, 부사) 세 가지를 사용하여 딕셔너리를 구성하였고,
22tags일때는 
	'NC':'보통명사',
	'NQ':'고유명사',
	'NB':'의존명사',	
	'NN':'수사' ,
	'NP':'대명사' , 
	'PV':'동사', 
	'PA':'형용사',
	'PX':'보조 용언',
	'MM':'관형사' , 
	'MA':'부사',
이렇게 체언, 용언, 수식언에 해당하는 품사들만 사용하였다. 

실제 구현에서는 비교적 정보를 많이 나타내는 보통명사, 고유명사 두 가지만 사용하였다. 다른 품사도 사용하고 싶다면 hannanum_analyze_22함수 내에 해당 주석을 풀어서 사용하면 된다.

전체 품사들에 대해 알고싶다면 참조에 '한국어 품사 태그 비교표'를 참고하시기 바란다.

용언P같은 경우 의미를 제대로 파악 하기위해 형태소에 '-다'를 붙여 완전한 단어형태로 만들었다. 
예) 형태소 '먹'은 '-다'를 붙여 '먹다'로 저장

같은 형태소라도 상황에 따라 용언으로 해석될때가 있고 체언으로 해석될 때가 있는데 구분을 하지 않았다.
따로 구분하고 싶다면 wordgram_analyze내에 wordgram.hannanum_analyze_22 함수를 사용하시기 바란다.


참조
KoNLPy: 파이썬 한국어 NLP http://konlpy.org/ko/v0.4.3/
위키피디아-형태소 http://ko.wikipedia.org/wiki/형태소
한국어 품사 태그 비교표 https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0


3. 구현
data폴더내의 모든 텍스트파일을 읽어들여 형태소를 구하고 빈도수를 측정한다음 모두 합산하여 제일 빈도수가 높은 형태소부터 차례대로 나타낸다. 결과는 result1.txt파일에 저장한다.

tf-idf값을 이용해서 단어의 중요도를 분석하는 메소드도 구현하였다(tfidf.py참조) tf-idf값이란 한 문서에 나오는 단어들이, 다른 문서들에 비해 그 문서를 얼마나 잘 설명하는(특징적인) 단어인지 나타낸다.

만약 data1 문서에 'Good'이라는 단어가 자주 나오는데, data2 문서에도 자주 나타난다면, 'Good'은 data1의 특징적인 키워드가 아니므로 'Good'의 tf-idf값은 낮게 나와 중요도가 낮아진다.

tf-idf값의 결과값은 result2.txt에 저장한다.
참조: tf-idf http://blog.secmem.org/670
